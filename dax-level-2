#!/usr/bin/env python

from Pegasus.DAX3 import *
import sys
import os
import glob
import re

base_dir = sys.argv[1]
run_dir = sys.argv[2]

# Create a abstract dag
dax = ADAG("sub")

# Add executables to the DAX-level replica catalog
for exe_name in os.listdir(base_dir + "/tools/"):
    exe = Executable(name=exe_name, arch="x86_64", installed=False)
    exe.addPFN(PFN("file://" + base_dir + "/tools/" + exe_name, "local"))
    dax.addExecutable(exe)

results_list = []

# add processing jobs
chunk_dir = run_dir + "/chunks"
for chunk_filename in os.listdir(chunk_dir):

    # create Pegasus file objects
    input_file = File(chunk_filename)
    input_file.addPFN(PFN("file://" + chunk_dir + "/" + chunk_filename, "local"))
    dax.addFile(input_file)

    results_file = File(chunk_filename + ".results")
    dax.addFile(results_file)

    # Create a new job
    job = Job(name="process-chunk.sh")

    # files required/generated by the job
    job.uses(input_file, link=Link.INPUT)
    job.uses(results_file, link=Link.OUTPUT)

    job.addArguments(chunk_filename)
    dax.addJob(job)

    # keep track of the outputs so we can merge them later
    results_list.append(results_file)

# merge job
merged_results = File("merged.results")
dax.addFile(merged_results)

merge = Job(name="merge-results.sh")
merge.uses(merged_results, link=Link.OUTPUT)
merge.addArguments(merged_results)
for result in results_list:
    merge.uses(result, link=Link.INPUT)
    merge.addArguments(result)
dax.addJob(merge)

# Write the DAX to stdout
f = open(run_dir + "/level-2.xml", "w")
dax.writeXML(f)
f.close()

